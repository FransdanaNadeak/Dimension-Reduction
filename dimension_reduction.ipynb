{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe pretrained embeddings dimension reduction with PCA on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download GloVe files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "FmXn4NhIh4n9",
    "outputId": "db68bbfc-bb94-438f-e1d2-1a07d525e8ae"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def download(url, file):\n",
    "    if not os.path.isfile(file):\n",
    "        print(\"Download file... \" + file + \" ...\")\n",
    "        urlretrieve(url,file)\n",
    "        print(\"File downloaded\")\n",
    "\n",
    "download('https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip')\n",
    "print(\"All the files are downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncompress downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aj6pKJncn8s8"
   },
   "outputs": [],
   "source": [
    "def uncompress_features_labels(dir):\n",
    "    if(os.path.isdir('data')):\n",
    "        print('Data extracted')\n",
    "    else:\n",
    "        with ZipFile(dir) as zipf:\n",
    "            zipf.extractall('data')\n",
    "uncompress_features_labels('glove.6B.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper : https://arxiv.org/abs/1708.03629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BBwjt07kqh-0",
    "outputId": "e215e107-7ea0-45d5-da83-561dc636f00a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "import subprocess\n",
    "\n",
    "Glove = {}\n",
    "f = open('/content/data/glove.6B.300d.txt')\n",
    "dims = 300\n",
    "red_dims = 150\n",
    "file_text = \"glove.6b.300d\"\n",
    "\n",
    "print(\"Loading Word vectors.\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    Glove[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(\"Done.\")\n",
    "X_train = []\n",
    "X_train_names = []\n",
    "for x in Glove:\n",
    "        X_train.append(Glove[x])\n",
    "        X_train_names.append(x)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "pca_embeddings = {}\n",
    "\n",
    "# PCA to get Top Components\n",
    "pca =  PCA(n_components = dims)\n",
    "print(X_train.shape)\n",
    "print(np.mean(X_train))\n",
    "X_train = X_train - np.mean(X_train)\n",
    "X_fit = pca.fit_transform(X_train)\n",
    "U1 = pca.components_\n",
    "\n",
    "z = []\n",
    "\n",
    "# Removing Projections on Top Components\n",
    "for i, x in enumerate(X_train):\n",
    "\tfor u in U1[0:7]:        \n",
    "        \tx = x - np.dot(u.transpose(),x) * u \n",
    "\tz.append(x)\n",
    "\n",
    "z = np.asarray(z)\n",
    "\n",
    "# PCA Dim Reduction\n",
    "pca =  PCA(n_components = red_dims)\n",
    "X_train = z - np.mean(z)\n",
    "X_new_final = pca.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# PCA to do Post-Processing Again\n",
    "pca =  PCA(n_components = red_dims)\n",
    "X_new = X_new_final - np.mean(X_new_final)\n",
    "X_new = pca.fit_transform(X_new)\n",
    "Ufit = pca.components_\n",
    "\n",
    "X_new_final = X_new_final - np.mean(X_new_final)\n",
    "\n",
    "final_pca_embeddings = {}\n",
    "filename_reduced = \"{}_reduced_embeddings_{}.txt\".format(file_text, red_dims)\n",
    "embedding_file = open(filename_reduced, 'w')\n",
    "\n",
    "for i, x in enumerate(X_train_names):\n",
    "        final_pca_embeddings[x] = X_new_final[i]\n",
    "        embedding_file.write(\"%s\\t\" % x)\n",
    "        for u in Ufit[0:7]:\n",
    "            final_pca_embeddings[x] = final_pca_embeddings[x] - np.dot(u.transpose(),final_pca_embeddings[x]) * u \n",
    "\n",
    "        for t in final_pca_embeddings[x]:\n",
    "                embedding_file.write(\"%f\\t\" % t)\n",
    "        \n",
    "        embedding_file.write(\"\\n\")\n",
    "\n",
    "print(\"The Reduced Embedding is available at {0}\".format(filename_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fm1FmC3DxiRN",
    "outputId": "e4090598-0440-4083-be3a-b6b56614939c"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'glove.6b.300d_reduced_embeddings_150.txt'})\n",
    "uploaded.SetContentFile('glove.6b.300d_reduced_embeddings_150.txt')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dimension reduction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
